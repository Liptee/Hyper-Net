# Мульти-бинарная классификация с помощью CNN Hyper-Net
В данном репозитории представлена сверточная нейронная сеть с Hyper-Net с использованием мульти-бинарного подхода.

## Что такое мульти-бинарный подход?
Мульти-бинарный подход применяется для решения задач мульиклассификации. Его суть заключается в следующем:
1. Нам нужен мультиклассовый датасет.
2. Из мультиклассового датасета, мы создаем бинарные экземпляры датасета для каждого класса (например, если у нас есть 3 класса: *фон*, *машина*, *человек*, то мы должны создать 3 бинарных датасета, в котором будут следующие классы: 1. *фон* и *все остальное*, 2. *машина* и все остальное, 3. *человек* и все остальное).
3. После этого мы обучаем нейросеть для каждого бинарного датасета и на выходе получаем несколько моделей для предсказания определенного класса.
4. Оцениваем каждую из готовых моделей по метрике (например *precision*, *recall*, *f1-score*) и сортируем их по возрастанию метрики.
5. В отсортированном порядке наслаиваем результаты бинарных моделей друг на друга. Таким образом результаты бинарной модели будут наложены в самую последнюю очердь.

## Плюсы и минусы токого подходы
Самый большой минус заключается конечно же в затратах ресурсов на обучение и предсказание. Время увеличивается за счет:
- времени на разбиение оригинального набора данных на бинарные;
- обучении не одной, а нескольких нейросетей;
- время на оценку получившихся моделей и создание "сборщика" финального результата.
- предсказание не одного изображение, а нескольких и их сборка в один файл.

Это наверное единственный минус такого подхода. Какие же плюсы мы получаем за увеличенные ресурсо-затраты:
- нейросети для каждого класса независимы. То есть для поиска каждого класса, мы можем указать отдельные гиперпараметры сети и добиваться наилучшего результата работы каждой нейронной сети независимо. В идеале, мы должны добиться от всех "бинарок" наилучших возможных результатов метрик и использовать их. 
- из первого плюса вытекает второй плюс. Если предположим класс *машина* нейронка различает хорошо, а *человека* плохо, нам не надо переобучать всю модель, а только ту ее часть, которая отвечает за поиск *человека*.
- мы можем пренебречь точностью поиска некоторых классов в угоду другим при установке настроек "сборщика". Если вам нужны какие-то особенные требования к классификации, например вам не важно количество ошибок первого рода для конкретного класса. Тогда в настройках "сборщика" вы можете вручную указать порядок сборки, указывая свои предпочтения по результату.

# Инструкция по текущему репозиторию
1. Скачайте репозиторий 
```cmd
git clone https://github.com/Liptee/Hyper-Net
```
3. Можете установить виртуальное окружение из `Pipfile`
2. В папку `dataset` положите два `.mat` файла гиперспектров (сам гиперкуб и его маску).
3. Зайдите в `config.py` и укажиьте путь до ваших файлов, а также индекс `np.array` в вашем файле.
4. Комментированием можете выбрать функцию потерь, видеокарту или процессор в качестве места вычислений и настроить гиперпараметры.
5. Запустите **python** файл `main.py`.
6. Бинарные маски сохранятся в `./checkpoints/bi_masks`. 
7. Модели сохранятся в `./checkpoints/models`.
8. Готовые предсказания сохранятся в `./checkpoints/res`.